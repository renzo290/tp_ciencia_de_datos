# -*- coding: utf-8 -*-
"""icd_2023_falciglia_renzo.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16i_f5FIZks4SU768xQ5db_RgL6Jsg501
"""

#TP Final Ciencia de datos

#Paquetes
import pandas as pd
import os
from pathlib import Path
from google.colab import drive
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score
from sklearn.model_selection import GridSearchCV
from sklearn.tree import DecisionTreeClassifier
from sklearn.tree import plot_tree
import matplotlib.pyplot as plt
from sklearn.model_selection import cross_val_score
import numpy as np
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.model_selection import cross_val_score
import seaborn as sns
import matplotlib.pyplot as plt
from scipy.stats import chi2_contingency
from sklearn.ensemble import RandomForestClassifier

#Se cargan los datos descargados desde https://www.kaggle.com/datasets/jessemostipak/hotel-booking-demand

# Ruta en Drive
ruta = '/content/drive/My Drive/10 - Maestría Economía Aplicada/Ciencia de datos/TP Final/Datos/hotel_bookings.csv'

# Cargar el archivo CSV
data = pd.read_csv(ruta)
data = pd.DataFrame(data)

#Análisis exploratorio

tipo = type(data)
nombres_columnas = data.columns

print(tipo)
print(nombres_columnas)

#Inciso 1 A
data.info()

#Inciso 1 B
#Creo representación gráfica para cancelaciones previas entre los grupos que cancelaron y los que no

cancelaron = data[data['is_canceled'] == 1]['previous_cancellations'].sum()
no_cancelaron = data[data['is_canceled'] == 0]['previous_cancellations'].sum()

#Se crea un gráfico de barras
fig, ax = plt.subplots()

bar_width = 0.35
groups = ['Cancelaron', 'No Cancelaron']

#Se crean las barras con las sumas de cancelaciones previas
plt.bar(groups, [cancelaron, no_cancelaron], bar_width)

#Ajustes en el gráfico
plt.ylabel('Cantidad de Reservas canceladas previamente')
plt.show()

#Inciso 1 B
canceled = data[data['is_canceled'] == 1]
not_canceled = data[data['is_canceled'] == 0]

#Se crea un gráfico de dispersión con colores para cada grupo
plt.figure(figsize=(10, 6))
plt.scatter(canceled['previous_cancellations'], canceled['lead_time'], label='Cancelado', alpha=0.5, color='red')
plt.scatter(not_canceled['previous_cancellations'], not_canceled['lead_time'], label='No cancelado', alpha=0.5, color='blue')

#Ajustes en el gráfico
plt.xlabel('Lead Time')
plt.ylabel('Cancelaciones previas')
plt.legend()
plt.show()

#Inciso 1 B
#Se agrupan los datos por segmento de mercado y se calcula el porcentaje de cancelaciones y no cancelaciones
segmento_cancelations = data.groupby('market_segment')['is_canceled'].value_counts(normalize=True).unstack().fillna(0) * 100

#Se crea un gráfico de barras
plt.figure(figsize=(10, 6))
segmento_cancelations.plot(kind='bar', stacked=True, color=['blue', 'red'], alpha=0.7)

#Ajustes en el gráfico
plt.xlabel('Segmento de Mercado')
plt.ylabel('Porcentaje')
plt.legend(['No Cancelado', 'Cancelado'], loc='center left', bbox_to_anchor=(1, 0.5))
plt.show()

#Inciso 1 C

#Se agrupan los datos por tipo de depósito y se calcula el porcentaje de cancelaciones y no cancelaciones
deposit_cancelations = data.groupby('deposit_type')['is_canceled'].value_counts(normalize=True).unstack().fillna(0) * 100

#Se crea un gráfico de barras apiladas
plt.figure(figsize=(10, 6))
deposit_cancelations.plot(kind='bar', stacked=True, color=['red', 'blue'], alpha=0.7)

#Ajustes en el gráfico
plt.xlabel('Tipo de Depósito')
plt.ylabel('Porcentaje')
plt.legend(['Cancelado', 'No Cancelado'], loc='center left', bbox_to_anchor=(1, 0.5))
plt.show()

#Inciso 1 C

#Se crea una tabla de contingencia (matriz de frecuencia)
contingency_table = pd.crosstab(data['deposit_type'], data['is_canceled'])

#Se realiza el test de chi-cuadrado
chi2, p, _, _ = chi2_contingency(contingency_table)

# Imprime los resultados
print(f"Estadística de chi-cuadrado: {chi2}")
print(f"Valor p: {p}")

# Determina si la relación es estadísticamente significativa (usualmente con un nivel de significancia de 0.05)
alpha = 0.05
if p < alpha:
    print("La relación entre deposit_type e is_canceled es estadísticamente significativa.")
else:
    print("No hay evidencia suficiente para afirmar que existe una relación significativa entre deposit_type e is_canceled.")

#Inciso 1 D
#Exploración visual de relación entre lead_time y is_canceled

#Se crea un box plot con los cajas y bigotes en posición vertical
plt.figure(figsize=(8, 6))
data.boxplot(column='lead_time', by='is_canceled', vert=True)

#Ajustes del gráfico
plt.xlabel('Estado de la Reserva')
plt.ylabel('Tiempo entre la reserva y el viaje')
plt.xticks([1, 2], ['No Cancelada', 'Cancelada'])
plt.title('')
plt.show()

#Inciso 2 A

#Se definen las variables de entrada (X) y la variable objetivo (y)
X = data.drop(columns=['is_canceled'])  #Características
y = data['is_canceled']  #Variable objetivo

#Se define una semilla aleatoria basada en el número de documento
numero_documento = 111111101  # Cambia este valor si lo deseas

#Se realiza una partición estratificada
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=numero_documento)

#El argumento 'stratify' asegura una estratificación según 'y' (is_canceled)
# y 'random_state' utiliza 'numero_documento' como semilla

#Se verifican  las formas de los conjuntos de entrenamiento y prueba
print("Forma de X_train:", X_train.shape)
print("Forma de X_test:", X_test.shape)
print("Forma de y_train:", y_train.shape)
print("Forma de y_test:", y_test.shape)

#Inciso 2 B

#Se crea una lista de predictores categóricos
atributos_categoricos = ['market_segment', 'distribution_channel', 'is_repeated_guest', 'deposit_type', 'customer_type']

#Se crea una lista de predictores numéricos
atributos_numericos = ['lead_time', 'stays_in_week_nights', 'children', 'previous_cancellations', 'previous_bookings_not_canceled',
                       'days_in_waiting_list']

#Para acceder a los datos numéricos y categóricos
datos_numericos = data[atributos_numericos]
datos_categoricos = data[atributos_categoricos]

#Evalúo si existen valores nulos en alguno de los atributos

#Se verifica la cantidad de valores faltantes en cada columna
faltantes = data.isnull().sum()
print(faltantes)

#Le asigno un 0 a los valores de la variable "children" que tienen NA
data['children'].fillna(0, inplace=True)

#Inciso 3 A

#Se crean de nuevo las divisiones del inciso 2, pero esta vez realizando las transformaciones one-hot encoding para los atributos categóricos

#Se dividen los datos en un conjunto de entrenamiento y un conjunto de prueba
X = data[atributos_categoricos]  #Se utilizan solo los atributos categóricos previamente definidos
y = data['is_canceled']  #Es la variable a estimar

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)  # Ajusta la proporción y la semilla

#Se crea un preprocesamiento que aplique one-hot encoding
preprocesamiento = ColumnTransformer(
    transformers=[
        ('cat', OneHotEncoder(), atributos_categoricos)
    ],
    remainder='passthrough'
)

#Se crea el pipeline que incluye el preprocesamiento y el modelo de árbol de clasificación
pipeline = Pipeline([
    ('preproceso', preprocesamiento),
    ('modelo', DecisionTreeClassifier(random_state=42))
])

#Se entrena el modelo
pipeline.fit(X_train, y_train)

#Se realizan las predicciones en el conjunto de prueba
y_pred = pipeline.predict(X_test)

#Inciso 3 B
#Se evalúa rendimiento con Accuracy-Score
accuracy = accuracy_score(y_test, y_pred)
print(f"Precisión del modelo (Accuracy): {accuracy}")

#Se evalúa rendimiento con la matriz de confusión
conf_matrix = confusion_matrix(y_test, y_pred)
print("Matriz de Confusión:")
print(conf_matrix)

#Se evalúa rendimiento con el cálculo de la precision
precision = precision_score(y_test, y_pred)
print("Precisión:", precision)

#Se evalúa rendimiento con el cálculo del recall
recall = recall_score(y_test, y_pred)
print("Recall:", recall)

#Se evalúa rendimiento con el cálculo del  F1-score
f1 = f1_score(y_test, y_pred)
print("F1-Score:", f1)

#Inciso 3 C
#Para asegurar que se apliquen las mismas transformaciones a los datos de entrenamiento y de prueba
#Se combinan los datos de entrenamiento y prueba
X_combined = pd.concat([X_train, X_test], axis=0)

#Se crea un nuevo ColumnTransformer que se ajusta a ambos conjuntos de datos
preprocesamiento_combined = ColumnTransformer(
    transformers=[
        ('cat', OneHotEncoder(), atributos_categoricos)
    ],
    remainder='passthrough'
)

#Se ajusta el ColumnTransformer a los datos combinados
preprocesamiento_combined.fit(X_combined)

#Se transforman los datos de entrenamiento y prueba utilizando el ColumnTransformer combinado
X_train_encoded = preprocesamiento_combined.transform(X_train)
X_test_encoded = preprocesamiento_combined.transform(X_test)

#Inciso 3 C
#Se define un diccionario de hiperparámetros que se desean ajustar
param_grid = {
    'modelo__max_depth': [None, 10, 20, 30],  #Profundidad del árbol
    'modelo__criterion': ['gini', 'entropy']  #Criterio de división
}

#Se crea un objeto GridSearchCV para realizar la búsqueda en cuadrícula.

grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, cv=5, scoring='accuracy', verbose=1, n_jobs=-1)

#Se ajusta el modelo con la búsqueda en cuadrícula en los datos de entrenamiento:
grid_search.fit(X_train, y_train)

#Inciso 3 C
#Se acceden a los mejores hiperparámetros y a la precisión del mejor modelo:
best_params = grid_search.best_params_
best_accuracy = grid_search.best_score_

print("Mejores hiperparámetros encontrados:", best_params)
print("Precisión del mejor modelo:", best_accuracy)

#Inciso 3 C
#Se encuentra  el árbol de decisión óptimo con los mejores hiperparámetros
best_tree = grid_search.best_estimator_.named_steps['modelo']

# Visualizar el árbol de decisión con los mejores hiperparámetros
plt.figure(figsize=(15, 10))
plot_tree(best_tree, feature_names=preprocesamiento.get_feature_names_out(input_features=atributos_categoricos), filled=True, rounded=True, class_names=['Not Canceled', 'Canceled'])
plt.show()

#Inciso 3 C

#Se limita la profundidad del árbol para que no sea tan grande
max_depth_to_show = 3

plt.figure(figsize=(15, 10))
plot_tree(best_tree, feature_names=preprocesamiento.get_feature_names_out(input_features=atributos_categoricos), filled=True, rounded=True, class_names=['Not Canceled', 'Canceled'], max_depth=max_depth_to_show)
plt.show()

#Inciso 3 C
#Se especifica el número de folds (cv=5 para 5-fold cross-validation)
num_folds = 5

#Se realiza la validación cruzada y obtén la precisión en cada fold
scores = cross_val_score(best_tree, X_train_encoded, y_train, cv=num_folds, scoring='accuracy')

#Se calcula la precisión promedio
average_accuracy = scores.mean()

print(f'Precisión promedio en {num_folds}-fold cross-validation: {average_accuracy:.3f}')

#Inciso 3 D
#Se crea el mismo modelo que en el inciso A, pero también con parámetros numéricos

#Se define el preprocesamiento
preprocesamiento = ColumnTransformer(
    transformers=[
        ('cat', OneHotEncoder(handle_unknown='ignore'), atributos_categoricos),
        ('num', StandardScaler(), atributos_numericos)
    ],
    remainder='passthrough'
)

#Se aplica el preprocesamiento a todos los atributos (categóricos y numéricos)
X_preprocesado = preprocesamiento.fit_transform(data[atributos_categoricos + atributos_numericos])

#Se dividen los datos
X_train, X_test, y_train, y_test = train_test_split(X_preprocesado, data['is_canceled'], test_size=0.2, random_state=42)

#Se entrena el modelo
modelo = DecisionTreeClassifier(random_state=42)
modelo.fit(X_train, y_train)
y_pred = modelo.predict(X_test)

#Inciso 3 D
#Ahora se evalúa de la misma manera que el modelo del inciso A, al modelo recién confeccionado y que tiene tanto
#los atributos numéricos como los categóricos

#Se evalúa rendimiento con Accuracy-Score
accuracy = accuracy_score(y_test, y_pred)
print(f"Precisión del modelo (Accuracy): {accuracy}")

#Se evalúa rendimiento con la matriz de confusión
conf_matrix = confusion_matrix(y_test, y_pred)
print("Matriz de Confusión:")
print(conf_matrix)

#Se evalúa rendimiento con el cálculo de la precision
precision = precision_score(y_test, y_pred)
print("Precisión:", precision)

#Se evalúa rendimiento con el cálculo del recall
recall = recall_score(y_test, y_pred)
print("Recall:", recall)

#Se evalúa rendimiento con el cálculo del  F1-score
f1 = f1_score(y_test, y_pred)
print("F1-Score:", f1)

#Inciso 3 E

#Se define el espacio de búsqueda de hiperparámetros para el árbol de decisión
param_grid = {
    'max_depth': [3, 4, 5, 6],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}

#Se crea un estimador de DecisionTreeClassifier
modelo = DecisionTreeClassifier(random_state=42)

#Se crea un objeto GridSearchCV con el estimador y el espacio de hiperparámetros
grid_search = GridSearchCV(estimator=modelo, param_grid=param_grid, cv=5, scoring='accuracy')

#Se realiza la búsqueda de hiperparámetros en los datos de entrenamiento
grid_search.fit(X_train, y_train)

#Inciso 3 E
#Se obtienen los mejores hiperparámetros encontrados
best_params = grid_search.best_params_

#Se evalúa el modelo con los mejores hiperparámetros en los datos de prueba
best_model = grid_search.best_estimator_
y_pred = best_model.predict(X_test)

#Se imprime los mejores hiperparámetros y la precisión en los datos de prueba
print("Mejores hiperparámetros:", best_params)
print("Precisión en los datos de prueba:", accuracy_score(y_test, y_pred))

#Inciso 3 E
#Se evalúa el modelo con los mejores hiperparámetros en los datos de prueba
y_pred = best_model.predict(X_test)

#Se evalúa el rendimiento promedio
best_avg_score = grid_search.best_score_
print("Rendimiento promedio (accuracy):", best_avg_score)

#Inciso 3 E
#Se calcula la puntuación de validación cruzada (5-fold cross-validation)
cross_val_scores = cross_val_score(best_model, X_train, y_train, cv=5, scoring='accuracy')

#Se imprime las puntuaciones de validación cruzada
print("Puntuaciones de validación cruzada:", cross_val_scores)

#Se calcula la puntuación promedio de validación cruzada
mean_score = cross_val_scores.mean()
print("Puntuación promedio de validación cruzada:", mean_score)

#Inciso 4 A
#Se obtiene el mejor árbol de decisión y se lo grafica
best_tree = best_model

plt.figure(figsize=(15, 10))
plot_tree(best_tree, feature_names=data.columns, class_names=['Not Canceled', 'Canceled'], filled=True, rounded=True)
plt.show()

#Inciso 4 A
#Se ajustan los parámetros del árbol para controlar su tamaño
plt.figure(figsize=(10, 6))  # Establecer el tamaño de la figura
plot_tree(best_tree, feature_names=data.columns, class_names=['Not Canceled', 'Canceled'], filled=True, rounded=True, max_depth=3)
plt.show()

#Inciso 4 B

#Se obtiene la importancia de las características
feature_importance = best_model.feature_importances_

#Se obtienen los nombres de las características
feature_names = atributos_numericos + atributos_categoricos

#Para que feature_importance y feature_names tengan la misma longitud
n = min(len(feature_importance), len(feature_names))
feature_importance = feature_importance[:n]
feature_names = feature_names[:n]

#Se crea un DataFrame para mostrar las importancias de las características junto con sus nombres
importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importance})
importance_df = importance_df.sort_values(by='Importance', ascending=False)

#Se visualiza la importancia de las características
print(importance_df)

#Inciso 4 C

#Se entrena el árbol de decisión con todo el conjunto de datos de entrenamiento
best_model.fit(X_train, y_train)

#Se realizan predicciones en el conjunto de prueba
y_pred = best_model.predict(X_test)

#Inciso 4 C
#Se evalúa el rendimiento

#Se calcula la precisión
accuracy = accuracy_score(y_test, y_pred)
print(f"Precisión (Accuracy) en datos de prueba: {accuracy:.2f}")

#Se calcula el recall
recall = recall_score(y_test, y_pred)
print(f"Recall en datos de prueba: {recall:.2f}")

#Se calcula la precisión
precision = precision_score(y_test, y_pred)
print(f"Precisión en datos de prueba: {precision:.2f}")

#Se evalúa rendimiento con el cálculo del  F1-score
f1 = f1_score(y_test, y_pred)
print("F1-Score:", f1)

#Se genera la matriz de confusión
conf_matrix = confusion_matrix(y_test, y_pred)
print("Matriz de Confusión:")
print(conf_matrix)

#Se grafica la matriz de confusión
plt.figure(figsize=(6, 4))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Predicción')
plt.ylabel('Valor Real')
plt.title('Matriz de Confusión')
plt.show()

#Inciso 5

#Se crea un modelo de Random Forest
random_forest_model = RandomForestClassifier(random_state=42)

#Se entrena el modelo con el conjunto de datos de entrenamiento
random_forest_model.fit(X_train, y_train)

#Se realizan predicciones en el conjunto de prueba
y_pred_rf = random_forest_model.predict(X_test)

#Inciso 5

#Se evalúa el rendimiento del modelo de Random Forest

#Se calcula la precisión (Accuracy)
accuracy_rf = accuracy_score(y_test, y_pred_rf)
print(f"Precisión (Accuracy) en datos de prueba (Random Forest): {accuracy_rf:.2f}")

#Se calcula el recall
recall_rf = recall_score(y_test, y_pred_rf)
print(f"Recall en datos de prueba (Random Forest): {recall_rf:.2f}")

#Se calcula la precisión
precision_rf = precision_score(y_test, y_pred_rf)
print(f"Precisión en datos de prueba (Random Forest): {precision_rf:.2f}")

#Se generar la matriz de confusión
conf_matrix_rf = confusion_matrix(y_test, y_pred_rf)
print("Matriz de Confusión (Random Forest):")
print(conf_matrix_rf)

#Se evalúa rendimiento con el cálculo del  F1-score
f1 = f1_score(y_test, y_pred_rf)
print("F1-Score:", f1)

#Se graficar la matriz de confusión del modelo de Random Forest
plt.figure(figsize=(6, 4))
sns.heatmap(conf_matrix_rf, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Predicción')
plt.ylabel('Valor Real')
plt.show()